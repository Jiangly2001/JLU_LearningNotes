# 计算机系统结构

## 第一章 概述

### 1.1 引言

![image-20220808164130363](D:\markdown projects\pic\image-20220808164130363.png)

#### 计算机Flynn分类

> 依据数据流（指令流调用的数据序列）、指令流（计算机执行的指令序列）并行

* SISD 单指令流、单数据流
* SIMD 单指令流、多数据流
* MISD 多指令流、单数据流 :x:
* SIMD 单指令流、多数据流

#### 应用程序并行分类

* 数据级并行（DLP）：同时操作许多数据项。
* 任务级并行（TLP）：创建了一些能够单独处理但大量采用并行方式执行的工作任务。

### 1.2 计算机体系结构定义

* 狭义：机器语言程序员所见到的计算机的属性，即概念性结构和功能特性
* 广义：包括计算机设计的所有三个方面——指令集结构、组成和硬件

### 1.3 发展趋势

![image-20220808170336862](D:\markdown projects\pic\image-20220808170336862.png)

### 1.4 性能测试

![image-20220808170435572](D:\markdown projects\pic\image-20220808170435572.png)

* 响应时间/执行时间
  * 性能：<img src="D:\markdown projects\pic\image-20220808171229764.png" alt="image-20220808171229764" style="zoom:50%;" />
* 吞吐量：单位时间内完成任务量
* 加速比：机器X比机器Y快 <=><img src="D:\markdown projects\pic\image-20220808171459237.png" alt="image-20220808171459237" style="zoom:50%;" />
  * 速度：<img src="D:\markdown projects\pic\image-20220808171208673.png" alt="image-20220808171208673" style="zoom:50%;" />
* 墙上/时钟时间：包括所有的系统开销
  * 时钟时间 ＝ 阻塞时间 ＋ 就绪时间 ＋运行时间（CPU时间）
* CPU时间
  * 用户CPU时间+系统CPU时间=**运行时间**
    * 用户CPU时间 ＝ 运行状态下用户空间的时间
    * 系统CPU时间 = 运行状态下系统空间的时间

* 基准测试
  * 程序内核 ：实际应用程序中的短小、关键部分
  * 玩具程序：为了完成编程入门作业而编写的小程序，通常不超过100行，如快排程序
  * 合成基准测试程序：为了匹配实际应用程序的特征和行为编写的虚拟程序
  * 基准测试套件：衡量处理器处理各种应用程序的性能

### 1.5计算机设计的量化原理

![image-20220808171901976](D:\markdown projects\pic\image-20220808171901976.png)



#### 并行

##### 并行性含义

计算机系统在**同一时刻（同时性）**或者**同一时间间隔内（并发性）**进行多种运算或操作。即只要在时间上相互重叠，就存在并行性。

##### 提高并行性③

* **时间重叠：** *引入时间因素*，让多个处理过程在时间上相互错开，*轮流重叠地使用同一套硬件设备的各个部分，*以加快硬件周转而赢得速度。
  * 单处理机中—部件功能专用化（指令流水线：把一件工作按功能分割为若干相互联系的部分；把每一部分指定给专门的部件完成；按时间重叠原理把各部分的执行过程在时间上重叠起来）
  * 多处理机中 – 处理机专用化（专用外围处理机、专用处理机、异构型多处理机系统）

* **资源重复：** *引入空间因素*，以数量取胜。通过*重复设置硬件资源*，大幅度地提高计算机系统的性能。
  * 单处理机中  -- 重复设置功能部件（多存储体并行、数据/指令独立存储体、重复设置运算部件）
  * 多处理机中 – 重复设置处理机（容错系统、同构型多处理机系统）

* **资源共享：**一种*软件*方法，它使多个任务按一定时间顺序*轮流使用同一套硬件设备*。
  * 单处理机中：分时系统
  * 多处理中：分布式系统

#### 局部性原理

程序执行时所访问的存储器地址分布不是随机的，为是相对的聚集。程序执行时间的90%都是在执行程序中10%的代码。分为时间局部性和空间局部性。

* 时间局部性指程序即将用到的信息很可能就是**目前正在使用的信息**。

* 空间局部性指程序即将用到的信息很可能**与目前正在使用的信息在空间上相邻或临近**。

#### Amdahl定律

##### 加速比

* 公式1

  <img src="D:\markdown projects\pic\image-20220808175746570.png" alt="image-20220808175746570" style="zoom: 50%;" />

* 公式2

<img src="D:\markdown projects\pic\image-20220808181000002.png" alt="image-20220808181000002" style="zoom:50%;" />

> 公式拓展：
>
> ![image-20220808181744181](D:\markdown projects\pic\image-20220808181744181.png)

* 依赖因素②
  * 可改进比例
  * 部件加速比

##### Amdahl定律

> 根据加速比公式

一种性能改进的递减规则，即如果仅仅对计算任务中的一部分做性能改进，则改进得越多，所得到的总体性能的提升就越有限。

* 重要推论：如果只针对整个任务的一部分进行改进和优化，那么所获得的加速比不超过<img src="D:\markdown projects\pic\image-20220808181359605.png" alt="image-20220808181359605" style="zoom: 33%;" />

#### CPU性能公式

* CPU时间 = IC ×CPI ×时钟周期时间 

* CPU时间 = IC ×CPI ×(1/时钟频率）

*CPI：每条指令执行的平均时钟周期数*

> 公式拓展①：
>
> <img src="D:\markdown projects\pic\image-20220808182123726.png" alt="image-20220808182123726" style="zoom: 50%;" />
>
> 公式拓展②：
>
> 平均CPI：
>
> <img src="D:\markdown projects\pic\image-20220808182321784.png" alt="image-20220808182321784" style="zoom:50%;" />
>
> CPU时间 = IC ×平均CPI ×时钟周期时间 

##### 降低CPU时间

<img src="D:\markdown projects\pic\image-20220808182458808.png" alt="image-20220808182458808" style="zoom: 50%;" />

#### 摩尔定律

单芯片上可容纳的晶体管*数目*，约每隔*18个月*便会增加一倍，*性能*也将提升一倍。

#### Dennard定律

*晶体管面积*的缩小使得其所消耗的*电压以及电流*会以差不多相同的比例缩小。也就是说，如果晶体管的大小减半，该晶体管的静态功耗将会降至四分之一（电压电流同时减半）。

## 第二章 缓存优化

### 2.2.1 Cache性能分析

<img src="D:\markdown projects\pic\image-20220809181256030.png" alt="image-20220809181256030" style="zoom:80%;" />

<img src="D:\markdown projects\pic\image-20220809180707384.png" alt="image-20220809180707384" style="zoom:33%;" />

#### 平均访存时间

![image-20220809180117028](D:\markdown projects\pic\image-20220809180117028.png)

#### 程序执行时间

![image-20220809180435972](D:\markdown projects\pic\image-20220809180435972.png)

### 2.2.2 Cache性能改进

<img src="D:\markdown projects\pic\image-20220809181119377.png" alt="image-20220809181119377" style="zoom:50%;" />

![image-20220809213133481](D:\markdown projects\pic\image-20220809213133481.png)

| 优化技术                      | 不命中率 | 不命中  开销 | 命中  时间 | 硬件  复杂度 | 说 明                                                       |
| ----------------------------- | -------- | ------------ | ---------- | ------------ | ----------------------------------------------------------- |
| 增加块大小                    | +        | **-**        |            | 0            | 实现容易；Pentium  4 的第二级Cache采用了128字节的块         |
| 增加Cache容量                 | +        |              |            | 1            | 被广泛采用，特别是第二级Cache                               |
| 提高相联度                    | +        |              | **-**      | 1            | 被广泛采用                                                  |
| 牺牲Cache                     | +        |              |            | 2            | AMD  Athlon采用了8个项的Victim  Cache                       |
| 伪相联Cache                   | +        |              |            | 2            | MIPS  R10000的第二级Cache采用                               |
| 硬件预取指令和数据            | +        |              |            | 2～3         | 许多机器预取指令，UltraSPARCⅢ预取数据                       |
| 编译器控制的预取              | +        |              |            | 3            | 需同时采用非阻塞Cache；有几种微处理器提供了对这种预取的支持 |
| 用编译技术减少Cache不命中次数 | +        |              |            | 0            | 向软件提出了新要求；有些机器提供了编译器选项                |

| 优化技术               | 不命中率 | 不命中  开销 | 命中  时间 | 硬件  复杂度 | 说 明                                                   |
| ---------------------- | -------- | ------------ | ---------- | ------------ | ------------------------------------------------------- |
| 两级Cache              |          | +            |            | 2            | 硬件代价大；两级Cache的块大小不同时实现困难；被广泛采用 |
| 使读不命中优先于写     |          | +            | -          | 1            | 在单处理机上实现容易，被广泛采用                        |
| 写缓冲归并             |          | +            |            | 1            | 与写直达合用，广泛应用                                  |
| 尽早重启动和关键字优先 |          | +            |            | 2            | 被广泛采用                                              |
| 非阻塞Cache            |          | +            |            | 3            | 在支持乱序执行的CPU中使用                               |

| 优化技术                | 不命中率 | 不命中  开销 | 命中  时间 | 硬件  复杂度 | 说 明                                                        |
| ----------------------- | -------- | ------------ | ---------- | ------------ | ------------------------------------------------------------ |
| 容量小且结构简单的Cache | -        |              | +          | 0            | 实现容易，被广泛采用                                         |
| 虚拟Cache               |          |              | +          | 2            | 对于小容量Cache来说实现容易，已被Alpha  21164和UltraSPARC  Ⅲ采用 |
| 流水化Cache访问         |          |              | +          | 1            | 被广泛采用                                                   |
| Trace Cache             |          |              | +          | 3            | Pentium  4采用                                               |

#### 降低不命中率⑧

**<font color='red'>三种类型的不命中（3C）</font>**

* 强制性不命中(Compulsory miss)——就是没有
  * 当第一次访问一个块时，该块*不在Cache中*，需从下一级存储器中调入Cache，这就是强制性不命中 *(冷启动不命中，首次访问不命中）*
* 容量不命中(Capacity miss ) ——容量不足
  * 如果程序执行时所需的块*不能全部调入*Cache中，则当某些块被替换后，若又重新被访问，就会发生不命中。这种不命中称为容量不命中。
* 冲突不命中(Conflict miss)——映射冲突
  * 在*组相联或直接映像Cache中*，若太多的块映像到同一组(块)中，则会出现该组中某个块被别的块替换(即使别的组或块有空闲位置)，然后又被重新访问的情况。这就是发生了冲突不命中 *(碰撞不命中，干扰不命中)*

**<font color='red'>降低不命中率方法</font>**

1. **增加块大小**：适当增加块大小，减少*强制不命中*；
   * 会增加不命中开销(减少Cache中块的数目);增加不命中开销

2. **增加Cache容量**：减少*容量不命中*；
   * 增加成本;增加命中时间

3. **提高相联度**：减少*冲突不命中*；
   * 增加命中时间

4. **伪相联Cache**：在逻辑上把直接映像Cache的空间*上下平分*为两个区，访问时伪相联Cache*先按直接映像*Cache的方式去处理，若*不命中则到另一区查找*，找到则发生伪命中，否则不命中；

5. **硬件预取**：利用存储器的空闲带宽预取指令和数据放入Cache/外缓冲器上；

6. **编译器预取**：在编译时加入预取指令，在数据被用到之前发出预取请求；

7. **编译器优化**：无需对硬件改动，对软件进行优化从而降低不命中率,如数组合并、内外循环交换、循环融合、分块等技术；

8. **牺牲Cache**：在Cache和它从下一级存储器数据的通路之间设置一个全相联的小Cache（牺牲Cache），用于存放被替换出去的块以备重用。

#### 降低不命中开销⑤

**<font color='red'>降低不命中开销方法</font>**

1. **两级Cache**：第一级Cache(L1)小而快，第二级Cache(L2)容量大

   * <img src="D:\markdown projects\pic\image-20220809205945434.png" alt="image-20220809205945434" style="zoom:67%;" />

   * ![image-20220809205811517](D:\markdown projects\pic\image-20220809205811517.png)

   > 评价第二级Cache时，应使用全局不命中率这个指标。它指出了在CPU发出的访存中，究竟有多大比例是穿过各级Cache，最终到达存储器的。

   * <img src="D:\markdown projects\pic\image-20220809210057398.png" alt="image-20220809210057398" style="zoom:67%;" />

2. **让读不命中优先于写**：在读不命中时，所读单元的最新值有可能还在写缓冲器中，尚未写入主存

3. **写缓冲合并**：把这次的写入地址与写缓冲器中已有的所有地址进行比较，看是否有匹配的项。如果有地址匹配而对应的位置又是空闲的，就把这次要写入的数据与该项合并。

4. **请求字处理技术**：从下一级存储器调入Cache的块中，只有一个字(请求字)是立即需要的，故应尽早把请求字发给CPU。相关技术有：尽早重启动、请求字优先。

5. **非阻塞Cache技术**：Cache不命中时仍允许CPU进行其他的命中访问。即允许“不命中下命中”

#### 降低命中时间④

1. **使用小容量、结构简单的Cache**
2. **虚拟Cache**：可以直接用虚拟地址进行访问的Cache。即对Cache进行索引时不必进行地址变换   
3. **Cache访问流水化**：对第一级Cache的访问按流水方式组织
4. **踪迹Cache**：存放CPU所执行的动态指令序列，包含了由分支预测展开的指令，该分支预测是否正确需要在取到该指令时进行确认。

## 第三章 指令级并行

<img src="D:\markdown projects\pic\image-20220810163726485.png" alt="image-20220810163726485" style="zoom:67%;" />

<img src="D:\markdown projects\pic\image-20220810163822522.png" alt="image-20220810163822522" style="zoom:67%;" />

### 指令级并行TLP

* 指令级并行

存在于指令一级即指令间的并行性, 主要是指机器语言一级, 如存储器访问指令、整型指令、浮点指令之间的并行性等。

* 流水线CPI

  `CPI流水线 = CPI理想 + 停顿结构冲突 + 停顿数据冲突 + 停顿控制冲突`

实际CPI往往远大于理想CPI，它是理想流水线的CPI加上各类停顿的时钟周期数

* 开发指令级并行问题

  * 相关：两条指令之间存在某种依赖关系 *程序固有属性*

    * **数据相关**：指令*j*与指令*i*数据相关

      * 指令j使用指令i产生的结果<font color='cornflowerblue'>（写后读）</font>
      * 指令j与指令k数据相关，而指令k又与指令i数据相关 *(传递性)* 

    * **名相关**：指令*j*与指令*i*之间的名相关

      * 反相关：指令*j*写的名与指令*i*读的名相同 <font color='cornflowerblue'>(读后写)</font>
      * 输出相关：指令*j*和指令*i*写相同的名<font color='cornflowerblue'>（写后写）</font>

      > * **换名技术**直接消除：通过改变指令中操作数的名来消除名相关（因为读后写和写后写数据之间没有谁依赖谁，只是名字相同，换个名字即可解决）
      >
      > > 名相关的两条指令之间并没有数据的传送。如果一条指令中的名改变了，并不影响另外一条指令的执行。

    * **控制相关**:由分支指令引起的相关

  * 流水线冲突：对于具体的流水线来说，由于相关等原因的存在，使得指令流中的下一条指令不能在指定的时钟周期执行 *流水线属性*

    * 结构冲突、数据冲突、控制冲突

<img src="D:\markdown projects\pic\image-20220810234611751.png" alt="image-20220810234611751" style="zoom:50%;" />

* 开发指令级并行问题解决
  * 保持相关，但**避免发生冲突**
    * 指令调度 -- 编译器静态调度
  * 通过代码变换，**消除相关**
    * 寄存器重命名 -- 寄存器换名消除WAR和WAW（换名技术消除名相关）

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200720214729435.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzYzMzc4NA==,size_16,color_FFFFFF,t_70)

* 程序顺序：由源程序确定的在**完全串行方式**下指令的执行顺序
* 对于正确地执行程序来说，必须保持的最关键的两个属性是：**数据流**和**异常行为**
  * 保持异常行为：无论怎么改变指令的执行顺序，都不能改变程序中异常的发生情况。即原来程序中是怎么发生的，改变执行顺序后还是怎么发生。
  * 数据流：指数据值从其产生者指令到其消费者指令的实际流动
  * 如果我们能做到保持程序的**数据相关**和**控制相关**，就能保持程序的数据流和异常行为
  * 仅仅保持数据相关性是不够的，只有再加上保持控制顺序，才能够保持程序顺序
* 开发指令级并行
  * 基于软件的静态开发方法
  * 基于硬件的动态开发方法
  * 硬件＋软件技术

### 循环展开和指令调度

> 指令延迟规定：
>
> | 产生结果的指令      | 使用结果的指令   | 延迟（时钟周期数） |
> | ------------------- | ---------------- | ------------------ |
> | 浮点计算            | 另一个浮点计算   | 3                  |
> | 浮点计算            | 浮点store（S.D） | 2                  |
> | 浮点load（L**.**D） | 浮点计算         | 1                  |
> | 浮点load（L.D）     | 浮点store（S.D） | 0                  |
>
> 分支的延迟：1个时钟周期
>
> 使用整数load指令结果的延迟：1个时钟周期

![image-20220810230216366](D:\markdown projects\pic\image-20220810230216366.png)

* 不进行调度

![image-20220810230252003](D:\markdown projects\pic\image-20220810230252003.png)

* 进行指令调度

![image-20220810232709714](D:\markdown projects\pic\image-20220810232709714.png)

> <img src="D:\markdown projects\pic\image-20220810233030202.png" alt="image-20220810233030202" style="zoom:50%;" />

* 循环展开未调度:每四个循环展开成一个循环

![image-20220810233558793](D:\markdown projects\pic\image-20220810233558793.png)

* 循环展开并调度:消除空转

![image-20220810234023359](D:\markdown projects\pic\image-20220810234023359.png)

### 动态调度解决数据冒险

![image-20220810234127809](D:\markdown projects\pic\image-20220810234127809.png)

* 乱序执行消除数据相关
  * ID段拆分：流出/读操作数

<img src="D:\markdown projects\pic\image-20220811001241469.png" alt="image-20220811001241469" style="zoom:50%;" />

![image-20220811001326817](D:\markdown projects\pic\image-20220811001326817.png)

> 指令的动态调度导致了指令的乱序执行，指令的乱序执行导致了有反相关和输出相关的指令进入流水线之后产生**读后写**冲突和**写后写**冲突（名相关）

* 寄存器换名消除名相关

![image-20220811003645671](D:\markdown projects\pic\image-20220811003645671.png)

#### Tomasulo算法

* 核心思想
  * 记录和检测指令相关，**操作数一旦就绪就立即执行(乱序)**，把发生RAW(<font color='red'>写后读！</font>数据相关)冲突的可能性减少到最小；
  * 通过**寄存器换名**来消除WAR冲突和WAW冲突(名相关)

* Tomasulo的基本结构

![image-20220811004952591](D:\markdown projects\pic\image-20220811004952591.png)

> * 保留站:浮点加法器有3个保留站RS：ADD1，ADD2，ADD3;浮点乘法器有2个保留站：MULT1，MULT2 
> * 浮点寄存器FP:共有16个浮点寄存器：F0，F2，F4，…，F30

![image-20220811010340420](D:\markdown projects\pic\image-20220811010340420.png)

* Tomasulo算法的优点：
  * 冲突检测和指令执行控制是分布的
    * 每个功能部件的保留站中的信息决定了什么时候指令可以在该功能部件开始执行
    * 计算结果通过**CDB直接**从产生它的保留站传送到所有需要它的功能部件，而不用经过寄存器
  * 消除了WAW冲突和WAR冲突导致的停顿
    * 使用保**留站进行寄存器换名**，并且操作数**一旦就绪**就将之放入保留站。     
* Tomasulo算法的执行步骤

要点三步：<img src="D:\markdown projects\pic\image-20220811010711275.png" alt="image-20220811010711275" style="zoom: 50%;" />

![image-20220811011247126](D:\markdown projects\pic\image-20220811011247126.png)

![image-20220811100444390](D:\markdown projects\pic\image-20220811100444390.png)

### 动态调度解决控制冒险

<img src="D:\markdown projects\pic\image-20220811102907371.png" alt="image-20220811102907371" style="zoom:67%;" />

* 动态分支预测技术：

  通过硬件技术，**在程序执行时**根据每一条转移指令过去的转移历史记录来预测下一次转移的方向。通过**提前预测分支方向**，减少或消除**控制相关**导致的流水线停顿。

* 动态和静态分支预测技术的区别

![image-20220811102541458](D:\markdown projects\pic\image-20220811102541458.png)

* 分支预测的有效性取决于

  分支指令的有效性不仅取决于其**预测的准确性**，而且与正确和不正确两种情况下的**分支开销**都有密切关系。这些分支开销是由流水线结构、预测的方法和预测错误时的恢复策略等诸因素决定的。

#### 分支历史表BHT

1. 分支历史表/分支预测缓冲器：这种方法是最简单的动态分支预测方法。它用BHT来记录分支指令最近一次或几次的执行情况（成功或不成功），并据进行预测。
2. 两位分支预测：分支预测和状态修改

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200721162230112.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzYzMzc4NA==,size_16,color_FFFFFF,t_70)

> * 在BHT方法中，只对分支是否成功进行预测，对分支目标地址没有提供支持
>
> :arrow_right: BHT方法只在以下情况下才有用：定分支是否成功所需的时间大于确定分支目标地址所需的时间。
> 前述5段经典流水线：由于判定分支是否成功和计算分支目标地址都是在ID段完成，所以BHT方法不会给该流水线带来好处。

#### 分支目标缓冲器BTB

* BTB表结构

  <img src="D:\markdown projects\pic\image-20220811104600512.png" alt="image-20220811104600512" style="zoom:67%;" />

* 流水线相关操作：若是分支指令：

  ![img](https://img-blog.csdnimg.cn/20200721164743140.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzYzMzc4NA==,size_16,color_FFFFFF,t_70)

  <img src="D:\markdown projects\pic\image-20220811104907790.png" alt="image-20220811104907790" style="zoom:50%;" />

  > 命中×预测错误  /   没命中  =>有延迟

#### 基于硬件的前瞻执行

* 前瞻执行：

![image-20220811110546608](D:\markdown projects\pic\image-20220811110546608.png)

* 三种思想

  * 动态分支预测：用来选择后续执行的指令

  * 在控制相关的结果尚未出来之前，前瞻地执行后续指令。

  * 用动态调度对基本块的各种组合进行跨基本块的调度。（基本程序块：如果 一串连续的代码除了入口和出口以外，不包含其他分支指令和转入点。）

    > 实质是数据流执行(data flow execution)：只要操作数有效，指令就执行

* 实现前瞻执行——扩充Tamosulo算法

  > 拆分Tomasulo算法的写结果：写结果、**确认**

  ![image-20220811111601746](D:\markdown projects\pic\image-20220811111601746.png)

  > 允许指令乱序执行，但必须顺序确认

* 前瞻执行的结构

![image-20220811112508946](D:\markdown projects\pic\image-20220811112508946.png)

* 前瞻执行的算法步骤

![image-20220811120917114](D:\markdown projects\pic\image-20220811120917114.png)

![image-20220811114744140](D:\markdown projects\pic\image-20220811114744140.png)



## 第四章 数据级并行

![a6e98aa4cf0d95891fcc0ee8a5d2b439.png](https://p.ananas.chaoxing.com/star3/origin/a6e98aa4cf0d95891fcc0ee8a5d2b439.png)

* 数据级并行（DLP）：无论是矩阵运算还是图形图像处理，其共性是对大量的数据施加同种变换

### 向量体系结构vsGPU体系结构

* **向量体系结构**：指令流水线深，ALU宽度窄；单次指令流水后能处理更多数据，掩盖不必要的流水线时间。

* **GPU体系结构**：指令流水线浅，ALU宽度宽；流水本身比较简单，直接对更多的数据进行并行激素那，同一时刻处理更多数据。

### 向量体系结构

* 向量专用特殊寄存器

![image-20220811161124229](D:\markdown projects\pic\image-20220811161124229.png)

* 循环间相关：对一个循环来说，如果各轮迭代之间存在相关性，则称为循环间相关，否则为循环间无关
* 可向量化：针对一组Mips指令描述的循环，如果满足循环间无关，则循环称为可向量化的，编译器可为其生成向量指令
* 指令编队（convoy）：由一组不包含结构冒险的向量指令组成，一个编队中的所有向量指令在硬件条件允许时可以并行执行

#### 向量体系结构的性能优化

* **多车道技术**：设置多个功能部件，使它们并行工作
* **链接技术**：当两条指令出现“写后读”相关（数据相关）时，若它们不存在功能部件冲突和向量寄存器(源或目的) 冲突，就有可能把它们所用的功能部件头尾相接，形成一个链接(长)流水线，进行流水处理

![image-20220811163259925](D:\markdown projects\pic\image-20220811163259925.png)

![image-20220811163309772](D:\markdown projects\pic\image-20220811163309772.png)

* **编队技术**：几条能在同一个时钟周期内一起开始执行的向量指令集合（不存在结构冲突；不存在数据冲突；存在数据冲突，但是可以链接）称为一个编队
* **分段开采技术**：*当向量的长度N大于向量寄存器的长度n时*，必须把长向量N分成长度固定为n的段，然后循环分段处理，每一次循环只处理一个向量段。这种技术称为分段开采技术